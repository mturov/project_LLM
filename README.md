# project_LLM
Стек: Python, Streamlit, Ollama.

Цель проекта: Создать интерактивный дашборд на основе Streamlit с использованием локальной LLM «Ollama». 
Проект был создан с целью продемонстрировать Human-All Colloboration Design - навык, при котором человек дополняет свою работу AI, а не дублируют друг друга. Основная аналитическая база проекта написана на Python и представляет собой разные группировки данных по определенным параметрам, создавая таким образом информационную базу для LLM.

Описание проекта:
Пользователь открывает сайт, где расположен интерактивный дашборд (все это работает на платформе Streamlit), где приведены ряд графиков с важными метриками. На этом этапе пользователю не обязательно использовать LLM, он может использовать для своей работы уже сделанные графики. 
Если же запрос пользователя не удовлетворяется графиками, показанными на Streamlit, он может ввести интересующий его вопрос в отдельное окно «Вопрос о данных:». Как только запрос будет отправлен, LLM начнет обрабатывать запрос, имея в своей информационной базе сгруппированные данные и предоставит график и таблицу в виде ответа.

Шаги по достижению цели:
1.	Загружается датасет с данными. Для проекта был взят датасет с Kaggle по продажам товаров электронной техники в разных регионах страны. После загрузки датасета создаются новые новые колонки данных с группировкой данных: данные группируются по прибыли, выручке, месяцам, регионам. Выясняется количество проданных товаров, средняя выручка и топ-продуктов. Переименовываются название колонок.
2.	Создается промт для LLM. В нем подробно описываем какие группировки сделаны, доступные задачи и как должен выглядеть ответ LLM для пользователя.
3.	Создается функция «process llm response», отвечающая за ответ LLM. 
4.	Создаются отдельные функции для каждого графика, который должен быть на странице Streamlit и удовлетворять базовые потребности пользователя без использования LLM.
5.	Затем создается основная функция «main», отвечающая за работу интерактивного дашборда. В функции сказано то, как будет выглядеть визуальная часть страницы и действия LLM в зависимости от вопроса пользователя.

Результат работы проекта:
- Открывается локальный сервер на основе Streamlit, где продемонстрированы графики и окно для ввода запроса для LLM;
- На основе запроса создается график от LLM;
- Если запроса нет, пользователь может выбрать ряд графиков слева, найдя решение своей задачи на одном из графиков.

Плюсы проекта, выявленные в ходе его разработки и тестирования:
1.	Отсутствует необходимость для пользователя фильтровать данные, когда есть возможность задать вопрос напрямую, например, «Какой продукт самый прибыльный в декабре прошлого года?».
2.	В зависимости от собранной заранее информационной базы для LLM, ответ на запрос пользователя может появится очень быстро.

Недостатки проекта, выявленные в ходе его разработки и тестирования:
1.	Для полноценной работы проекта необходимо собрать большую информационную базу – то есть, сделать группировку данных по разным параметрам. Чем больше данных – тем больше подготовки данных, что занимает много времени.
2.	Если в запросе есть информация, которая не была сгруппирована заранее – то запрос не будет выполнен.

Скриншоты графиков и запросов от LLM находятся в папке проекта и с ними можно ознакомиться.
